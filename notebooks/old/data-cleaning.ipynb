{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f4fbe2",
   "metadata": {},
   "source": [
    "#### Toulouse PB Election Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from data_loader import load_and_prepare_projects\n",
    "\n",
    "path_22 = '../data/projects2022.csv'\n",
    "path_24 = '../data/projects2024.csv'\n",
    "\n",
    "df, _ = load_and_prepare_projects(path_22, path_24)\n",
    "df24 = df[df['year'] == 2024]\n",
    "df22 = df[df['year'] == 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa66c1",
   "metadata": {},
   "source": [
    "#### 3. Topic Extraction\n",
    "I give 50 random projects from 2022 and 2024 (Title + Description), LLM reads them together and extracts relevants topics list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topic_input_df = pd.concat([df22.filter(['project_id', 'project_name', 'description']),\n",
    "                            df24.filter(['project_id', 'project_name', 'description'])\n",
    "                            ])\n",
    "\n",
    "topic_input_df_sample = topic_input_df.sample(n=50, random_state=42)\n",
    "\n",
    "print(topic_input_df_sample[['project_name']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a61f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = df22.project_name[0]\n",
    "description = df22.description[0]\n",
    "\n",
    "\n",
    "prompt = \"\"\"Je vais te présenter une liste de 50 projets citoyens, chacun avec un titre et une description. Ta tâche consiste à analyser l’ensemble des projets et à extraire une liste de thèmes ou de sujets communs qui représentent les principales orientations ou problématiques abordées par ces initiatives.\n",
    "\n",
    "Chaque thème doit être :\n",
    "\n",
    "Concis et représentatif.\n",
    "\n",
    "Basé sur le contenu réel des projets, sans être inventé.\n",
    "\n",
    "Accompagné d’une brève description (1 à 2 phrases).\n",
    "\n",
    "Merci de fournir une liste structurée de 20 à 30 thèmes, classés par ordre de pertinence.\n",
    "\n",
    "Voici la liste des projets :\n",
    "\"\"\"\n",
    "\n",
    "project_list_text = \"\"\n",
    "for i, row in topic_input_df_sample.iterrows():\n",
    "    project_list_text += f\"{i+1}. Titre: {row['project_name']}\\n   Description: {row['description']}\\n\\n\"\n",
    "\n",
    "full_prompt = prompt + \" \\n\" + project_list_text\n",
    "\n",
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY')) \n",
    "\n",
    "full_prompt = prompt + \"\\n\" + project_list_text\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": full_prompt}\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=4000\n",
    ")\n",
    "\n",
    "output_text = response.choices[0].message.content\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pattern = r\"\\d+\\.\\s+\\*\\*(.*?)\\*\\*\\s+- Description:\\s*(.*?)\\n(?:\\n|$)\"\n",
    "matches = re.findall(pattern, output_text, re.DOTALL)\n",
    "\n",
    "df_topics = pd.DataFrame(matches, columns=[\"topic\", \"description\"])\n",
    "df_topics.to_csv(\"data/topics_output.csv\", sep = \";\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07794bc",
   "metadata": {},
   "source": [
    "### 4. Topics Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5a096",
   "metadata": {},
   "source": [
    "#### 4. Projects Clasification into Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_prompt(topics, project_name, description):\n",
    "    \n",
    "    prompt = f\"\"\"Je vais te présenter un projet citoyen qui a été proposé dans le cadre d'une élection de budgets participatifs a Toulouse, France. Tu vas lire le titre et la description du projet, ainsi qu'une liste de sujets préalablement définis.\n",
    "\n",
    "    Ta tâche consiste à analyser le projet et à choisir le sujet le plus représentatif parmi ceux disponibles.\n",
    "\n",
    "    Si tu considères qu'aucun des sujets existants ne représente correctement le projet, tu peux proposer un nouveau sujet. Ce nouveau sujet doit être :\n",
    "\n",
    "    - Concis et représentatif.\n",
    "    - Non inventé ni trop générique.\n",
    "    - Basé sur le contenu réel du projet.\n",
    "    - Il doit inclure une courte description du sujet.\n",
    "\n",
    "    Voici la liste des sujets : {topics}\n",
    "\n",
    "    Titre du projet : {project_name}\n",
    "    Description : {description}\n",
    "\n",
    "    Réponds uniquement par le sujet choisi ou, si nécessaire, le nouveau sujet créé. Pas d'explication supplémentaire.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY')) \n",
    "\n",
    "topics = \", \".join(df_topics.topic.tolist())\n",
    "\n",
    "res  = []\n",
    "for i in df24.index:\n",
    "    \n",
    "    project_name = df24.project_name[i]\n",
    "    description = df24.description[i]\n",
    "    prompt = classification_prompt(topics, project_name, description)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=4000)\n",
    "    \n",
    "    output_text = response.choices[0].message.content\n",
    "    \n",
    "    d = {'project_id': df24.project_id[i], 'out': output_text}\n",
    "    \n",
    "    print(d)\n",
    "    res.append(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2024 = pd.DataFrame(res)\n",
    "#class2024.to_csv(\"data/project_topics_gpt4turbo.csv\", index=False ,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666b3d9",
   "metadata": {},
   "source": [
    "#### 5. Get Project Embeddings (OpenAI Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3683c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY')) \n",
    "\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\", \n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "df24['text'] = df24['project_name'] + \": \" + df24['description']\n",
    "df24['embedding'] = df24['text'].apply(lambda x: get_embedding(x))\n",
    "df24['embedding'] = df24['embedding'].apply(lambda x: np.array(x).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6773a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2024.filter(['project_id', 'project_name', 'embedding']).to_csv(\"proj2024_embeddings_openai-3-large.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071d31f",
   "metadata": {},
   "source": [
    "#### All-Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "embedding_df2022 = pd.read_csv('data/proj2022_embeddings_openai-3-large.csv')\n",
    "embedding_df2022['embedding'] = embedding_df2022['embedding'].apply(ast.literal_eval)\n",
    "\n",
    "embedding_df2024 = pd.read_csv('data/proj2024_embeddings_openai-3-large.csv')\n",
    "embedding_df2024['embedding'] = embedding_df2024['embedding'].apply(ast.literal_eval)\n",
    "\n",
    "embedding_df = pd.concat([embedding_df2022, embedding_df2024]).reset_index(drop=True)\n",
    "embedding_df['embedding'] = embedding_df['embedding'].apply(np.array)\n",
    "\n",
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2022= pd.read_csv('data/proj2022_topics_gpt4-turbo.csv', sep=\";\")\n",
    "class2024= pd.read_csv('data/proj2024_topics_gpt4-turbo.csv', sep=\";\")\n",
    "\n",
    "pclass = pd.concat([class2022,class2024])\n",
    "pclass\n",
    "\n",
    "t1 = pd.merge(left=embedding_df, right=pclass, on='project_id', how = \"left\")\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1de384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embeddings_array = np.array(t1.embedding.values.tolist())\n",
    "print(embeddings_array.shape)\n",
    "\n",
    "pca_model = PCA(n_components = 2)\n",
    "pca_model.fit(embeddings_array)\n",
    "\n",
    "pca_embeddings_values = pca_model.transform(embeddings_array)\n",
    "print(pca_embeddings_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ae8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "fig = px.scatter(\n",
    "    x = pca_embeddings_values[:,0], \n",
    "    y = pca_embeddings_values[:,1],\n",
    "    color = t1['out'].values,\n",
    "    hover_name = t1['project_name'].values,\n",
    "    title = 'OpenAI 3 - Large Embeddings Model. Projects 2022 / 2024', width = 800, height = 600,\n",
    "    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title = 'first component', \n",
    "    yaxis_title = 'second component')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_model = TSNE(n_components=2, random_state=42)\n",
    "tsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=tsne_embeddings_values[:, 0],\n",
    "    y=tsne_embeddings_values[:, 1],\n",
    "    color=t1['out'].values,\n",
    "    hover_name=t1['project_name'].values,\n",
    "    #size=df2022['votes'].values,\n",
    "    size_max=30,                    \n",
    "    title='t-SNE embeddings. Proj 2022 / 2024',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    color_discrete_sequence=plotly.colors.qualitative.Alphabet_r\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='first component', \n",
    "    yaxis_title='second component'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558423b",
   "metadata": {},
   "source": [
    "#### 6. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import tqdm\n",
    "\n",
    "silhouette_scores = []\n",
    "for k in tqdm.tqdm(range(2, 51)):\n",
    "    kmeans = KMeans(n_clusters=k, \n",
    "                    random_state=42, \n",
    "                    n_init = 'auto').fit(embeddings_array)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    silhouette_scores.append(\n",
    "        {\n",
    "            'k': k,\n",
    "            'silhouette_score': silhouette_score(embeddings_array, \n",
    "                kmeans_labels, metric = 'cosine')\n",
    "        }\n",
    "    )\n",
    "\n",
    "fig = px.line(pd.DataFrame(silhouette_scores).set_index('k'),\n",
    "       title = '<b>Silhouette scores for K-means clustering</b>',\n",
    "       labels = {'value': 'silhoutte score'}, \n",
    "       color_discrete_sequence = plotly.colors.qualitative.Alphabet)\n",
    "fig.update_layout(showlegend = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, \n",
    "                    random_state=42, \n",
    "                    n_init = 'auto').fit(embeddings_array)\n",
    "kmeans_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne_model = TSNE(n_components=2, random_state=42)\n",
    "#tsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\n",
    "\n",
    "pca_model = PCA(n_components = 2)\n",
    "pca_model.fit(embeddings_array)\n",
    "pca_embeddings_values = pca_model.transform(embeddings_array)\n",
    "\n",
    "fig = px.scatter(\n",
    "    #x = tsne_embeddings_values[:,0], \n",
    "    #y = tsne_embeddings_values[:,1],\n",
    "    x = pca_embeddings_values[:,0],\n",
    "    y = pca_embeddings_values[:,1],\n",
    "    color = list(map(lambda x: 'cluster %s' % x, kmeans_labels)),\n",
    "    hover_name = t1.project_name.values,\n",
    "    #size=t1['votes'].values,\n",
    "    size_max=30,           \n",
    "    title = 'Clusters over Large Embedding Model. Projects 2022 / 2024', width = 800, height = 600,\n",
    "    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title = 'first component', \n",
    "    yaxis_title = 'second component')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1['cluster'] = list(map(lambda x: 'cluster %s' % x, kmeans_labels))\n",
    "cluster_stats_df = t1.reset_index().pivot_table(\n",
    "    index = 'cluster', values = 'project_id', \n",
    "    aggfunc = 'count', columns = 'out').fillna(0).applymap(int)\n",
    "\n",
    "cluster_stats_df = cluster_stats_df.apply(\n",
    "  lambda x: 100*x/cluster_stats_df.sum(axis = 1))\n",
    "\n",
    "fig = px.imshow(\n",
    "    cluster_stats_df.values, \n",
    "    x = cluster_stats_df.columns,\n",
    "    y = cluster_stats_df.index,\n",
    "    text_auto = '.2f', aspect = \"auto\",\n",
    "    labels=dict(x=\"cluster\", y=\"fact topic\", color=\"share, %\"), \n",
    "    color_continuous_scale='pubugn',\n",
    "    title = '<b>Share of topics in each cluster</b>', height = 550)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[(t1.out=='Accessibilité et Mobilité Améliorée') & (t1.cluster=='cluster 1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f235a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1.filter(['project_id', 'cluster']).to_csv('proj2022_cluster.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c2487",
   "metadata": {},
   "source": [
    "#### Create a Project Vector Dataframe\n",
    "Create a project Vector with: Cost, District, Topic Cluster, PCA - Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = df22.filter(['project_id', 'cost', 'district_n','votes']).sort_values(by='votes', ascending=False).reset_index(drop=True)\n",
    "t1['ranking'] = t1.index +1\n",
    "\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Semantic Embeddings\n",
    "import ast\n",
    "\n",
    "embedding2022 = pd.read_csv('data/proj2022_embeddings_openai-3-large.csv')\n",
    "embedding2022['embedding'] = embedding2022['embedding'].apply(ast.literal_eval)\n",
    "embedding2022\n",
    "\n",
    "t2 = pd.merge(left=t1, right=embedding2022.filter(['project_id', 'embedding']), on='project_id', how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embeddings_array = np.array(t2.embedding.values.tolist())\n",
    "print(embeddings_array.shape)\n",
    "\n",
    "pca_model = PCA(n_components = 2)\n",
    "pca_model.fit(embeddings_array)\n",
    "\n",
    "pca_embeddings_values = pca_model.transform(embeddings_array)\n",
    "print(pca_embeddings_values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## District Dummy - Cost Norm\n",
    "dist_dummies = pd.get_dummies(t1['district_n'], prefix='dist_').astype(int)\n",
    "dist_dummies\n",
    "\n",
    "t2['cost_n'] = (t2['cost'] - t2['cost'].min()) / (t2['cost'].max() - t2['cost'].min())\n",
    "t2['dist_v'] = dist_dummies.values.tolist()\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745eea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([t2.filter(['cost']).values,pca_embeddings_values], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9669c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array(embedding_df['embedding'].tolist())\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(explained_variance_ratio, marker='o')\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza explicada acumulada')\n",
    "plt.title('Varianza explicada acumulada por número de componentes PCA')\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label='90% varianza explicada')\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', label='95% varianza explicada')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=150)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "X_reduced.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
